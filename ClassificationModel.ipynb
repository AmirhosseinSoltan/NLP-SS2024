{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ed9739-828e-46fc-88ed-b786eb68951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 16:08:15.414972: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-19 16:08:15.461075: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-19 16:08:16.113838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416aa5f8-98e9-469a-8980-4d6d62df4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('../Dataset_MovieSummaries/y_train1.csv')\n",
    "y_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "x_train = pd.read_csv('../Dataset_MovieSummaries/X_train1.csv')\n",
    "x_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "y_test = pd.read_csv('../Dataset_MovieSummaries/y_test1.csv')\n",
    "y_test.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "x_test = pd.read_csv('../Dataset_MovieSummaries/X_test1.csv')\n",
    "x_test.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad7bb7e-143a-42c2-a5a4-fd3e4c8ab4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edcf789d-0b4c-4274-b302-7f27d70afa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.reset_index(drop = True, inplace = True)\n",
    "y_train.reset_index(drop = True, inplace = True)\n",
    "x_val.reset_index(drop = True, inplace = True)\n",
    "y_val.reset_index(drop = True, inplace = True)\n",
    "x_test.reset_index(drop = True, inplace = True)\n",
    "y_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3005c82b-9baa-4e73-b734-7b3ded01556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asolta2s/myenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">512,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_59          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_60          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_61          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_62          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m512,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_59          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_59 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_76 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_60          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_60 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_77 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_61          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_61 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_78 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_62          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_62 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_79 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m780\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">854,732</span> (3.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m854,732\u001b[0m (3.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">852,300</span> (3.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m852,300\u001b[0m (3.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,432\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,BatchNormalization, Activation\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "import math\n",
    "\n",
    "def step_decay_schedule(initial_lr=0.001, decay_factor=0.5, step_size=10):\n",
    "    def schedule(epoch):\n",
    "        return max(initial_lr * math.pow(decay_factor, math.floor((1+epoch)/step_size)), 0.000001)\n",
    "    return LearningRateScheduler(schedule)\n",
    "    \n",
    "learning_rate = 0.0001  # Adjust this value as needed\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(x_train.shape[1],), kernel_initializer=glorot_uniform(),kernel_regularizer=l2(0.1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, kernel_initializer=glorot_uniform(),kernel_regularizer=l2(0.1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, kernel_initializer=glorot_uniform(),kernel_regularizer=l2(0.1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, kernel_initializer=glorot_uniform(),kernel_regularizer=l2(0.1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))  # Output layer with softmax activation for multiclass classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a82ad-3576-4935-b7c3-7d49a61e2388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.0758 - loss: 109.7114 - val_accuracy: 0.0546 - val_loss: 34.8234 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0753 - loss: 25.3946 - val_accuracy: 0.0546 - val_loss: 8.6774 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1240 - loss: 6.6890 - val_accuracy: 0.1269 - val_loss: 3.1294 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2176 - loss: 2.5317 - val_accuracy: 0.1269 - val_loss: 1.6314 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2394 - loss: 1.3506 - val_accuracy: 0.1269 - val_loss: 1.1167 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2703 - loss: 0.9285 - val_accuracy: 0.1269 - val_loss: 0.8962 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2815 - loss: 0.7435 - val_accuracy: 0.1269 - val_loss: 0.7993 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2967 - loss: 0.6769 - val_accuracy: 0.1269 - val_loss: 0.7516 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3013 - loss: 0.6377 - val_accuracy: 0.1331 - val_loss: 0.7212 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2923 - loss: 0.6081 - val_accuracy: 0.1814 - val_loss: 0.6376 - learning_rate: 3.5000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3133 - loss: 0.5665 - val_accuracy: 0.2398 - val_loss: 0.5991 - learning_rate: 3.5000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3016 - loss: 0.5601 - val_accuracy: 0.2896 - val_loss: 0.5817 - learning_rate: 3.5000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3158 - loss: 0.5625 - val_accuracy: 0.2748 - val_loss: 0.5553 - learning_rate: 3.5000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3092 - loss: 0.5551 - val_accuracy: 0.3380 - val_loss: 0.5644 - learning_rate: 3.5000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3221 - loss: 0.5632 - val_accuracy: 0.3112 - val_loss: 0.5556 - learning_rate: 3.5000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3196 - loss: 0.5635 - val_accuracy: 0.3260 - val_loss: 0.5544 - learning_rate: 3.5000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3239 - loss: 0.5693 - val_accuracy: 0.3408 - val_loss: 0.5651 - learning_rate: 3.5000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3087 - loss: 0.5688 - val_accuracy: 0.2753 - val_loss: 0.5586 - learning_rate: 3.5000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3109 - loss: 0.5635 - val_accuracy: 0.2968 - val_loss: 0.5556 - learning_rate: 3.5000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3148 - loss: 0.5452 - val_accuracy: 0.3102 - val_loss: 0.5111 - learning_rate: 2.4500e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3288 - loss: 0.5048 - val_accuracy: 0.3466 - val_loss: 0.5097 - learning_rate: 2.4500e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3331 - loss: 0.5017 - val_accuracy: 0.3298 - val_loss: 0.5062 - learning_rate: 2.4500e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3332 - loss: 0.5064 - val_accuracy: 0.3322 - val_loss: 0.5081 - learning_rate: 2.4500e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3471 - loss: 0.5058 - val_accuracy: 0.3748 - val_loss: 0.5113 - learning_rate: 2.4500e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3584 - loss: 0.5007 - val_accuracy: 0.3432 - val_loss: 0.5042 - learning_rate: 2.4500e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3364 - loss: 0.4972 - val_accuracy: 0.3480 - val_loss: 0.5071 - learning_rate: 2.4500e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3476 - loss: 0.4978 - val_accuracy: 0.3169 - val_loss: 0.5068 - learning_rate: 2.4500e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3557 - loss: 0.4958 - val_accuracy: 0.3236 - val_loss: 0.5060 - learning_rate: 2.4500e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3367 - loss: 0.5059 - val_accuracy: 0.3293 - val_loss: 0.5042 - learning_rate: 2.4500e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3616 - loss: 0.4872 - val_accuracy: 0.3193 - val_loss: 0.4814 - learning_rate: 1.7150e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m29/66\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3643 - loss: 0.4615"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 200\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                   shuffle=True,\n",
    "                   callbacks=[step_decay_schedule(initial_lr=0.0005, decay_factor=0.7, step_size=10),early_stopping ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ac4eb59-87a2-4cc1-843d-ca924f82942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8adaf6da-a3a7-4871-986a-aca407871f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3441 - loss: 0.4136\n",
      "Test Accuracy: 33.97%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a0d69c0-beff-4e25-bcb5-183ef934f616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Accuracy: 0.26\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Action       0.70      0.54      0.61       581\n",
      "Action/Adventure       0.69      0.53      0.60       576\n",
      "       Adventure       0.74      0.47      0.58       533\n",
      "          Comedy       0.69      0.33      0.45       646\n",
      "   Crime Fiction       0.68      0.40      0.50       421\n",
      "           Drama       0.71      0.60      0.65       970\n",
      "     Family Film       0.75      0.61      0.67       479\n",
      "          Horror       0.80      0.71      0.75       589\n",
      "    Romance Film       0.71      0.60      0.65       460\n",
      "  Romantic drama       0.74      0.63      0.68       408\n",
      "      Short Film       0.81      0.69      0.75       584\n",
      "        Thriller       0.61      0.43      0.50       536\n",
      "\n",
      "       micro avg       0.72      0.55      0.62      6783\n",
      "       macro avg       0.72      0.54      0.62      6783\n",
      "    weighted avg       0.72      0.55      0.62      6783\n",
      "     samples avg       0.66      0.56      0.58      6783\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asolta2s/myenv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred_binary, target_names=list(y_train.columns))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e38a8d8-2287-4134-89b6-0091b4e6d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cd786-ba19-480d-84b6-09f2768a4c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "early stopping \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73176a5d-2ceb-4ed9-a4b6-5a23d8734559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70bc7fe7-2a68-4525-a701-b35e38cd665f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Action              0\n",
       "Action/Adventure    0\n",
       "Adventure           0\n",
       "Black-and-white     1\n",
       "Comedy              0\n",
       "Crime Fiction       0\n",
       "Drama               0\n",
       "Family Film         0\n",
       "Horror              0\n",
       "Indie               0\n",
       "Romance Film        0\n",
       "Short Film          0\n",
       "Thriller            1\n",
       "World cinema        0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8862a2c-95cd-47eb-b382-60b0a15fb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "lr = LogisticRegression()\n",
    "clf = OneVsRestClassifier(lr)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479ae1e7-d345-4966-b2fe-2578c5266581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Action       0.72      0.42      0.53       581\n",
      "Action/Adventure       0.68      0.38      0.48       576\n",
      "       Adventure       0.73      0.34      0.47       533\n",
      "          Comedy       0.62      0.24      0.35       646\n",
      "   Crime Fiction       0.67      0.31      0.43       421\n",
      "           Drama       0.70      0.55      0.62       970\n",
      "     Family Film       0.80      0.44      0.57       479\n",
      "          Horror       0.83      0.53      0.65       589\n",
      "    Romance Film       0.77      0.39      0.52       460\n",
      "  Romantic drama       0.81      0.43      0.56       408\n",
      "      Short Film       0.88      0.59      0.70       584\n",
      "        Thriller       0.62      0.30      0.40       536\n",
      "\n",
      "       micro avg       0.74      0.42      0.54      6783\n",
      "       macro avg       0.74      0.41      0.52      6783\n",
      "    weighted avg       0.73      0.42      0.53      6783\n",
      "     samples avg       0.58      0.44      0.47      6783\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asolta2s/myenv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred_binary, target_names=list(y_train.columns))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "26327208-7b35-4ee7-9cba-ba6697944075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for label: Action\n",
      "[LightGBM] [Info] Number of positive: 1902, number of negative: 7066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _log_callback at 0x7f9c7c0c8b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asolta2s/myenv/lib64/python3.9/site-packages/lightgbm/basic.py\", line 255, in _log_callback\n",
      "    def _log_callback(msg: bytes) -> None:\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-choosing col-wise multi-threading, the overhead of testing was 2.193947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149772\n",
      "[LightGBM] [Info] Number of data points in the train set: 8968, number of used features: 1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212087 -> initscore=-1.312389\n",
      "[LightGBM] [Info] Start training from score -1.312389\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Train the model and get predictions\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     33\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "Cell \u001b[0;32mIn[153], line 19\u001b[0m, in \u001b[0;36mtrain_and_predict\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      8\u001b[0m lgb_eval \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_test, y_test\u001b[38;5;241m.\u001b[39miloc[:, i], reference\u001b[38;5;241m=\u001b[39mlgb_train)\n\u001b[1;32m     10\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_logloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.9\u001b[39m\n\u001b[1;32m     17\u001b[0m }\n\u001b[0;32m---> 19\u001b[0m gbm \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlgb_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m gbm\u001b[38;5;241m.\u001b[39mpredict(X_test, num_iteration\u001b[38;5;241m=\u001b[39mgbm\u001b[38;5;241m.\u001b[39mbest_iteration)\n\u001b[1;32m     26\u001b[0m predictions[:, i] \u001b[38;5;241m=\u001b[39m (y_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib64/python3.9/site-packages/lightgbm/engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    296\u001b[0m     cb(\n\u001b[1;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib64/python3.9/site-packages/lightgbm/basic.py:4126\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4125\u001b[0m _safe_call(\n\u001b[0;32m-> 4126\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4130\u001b[0m )\n\u001b[1;32m   4131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "early_stopping_callback = lgb.early_stopping(stopping_rounds=10)\n",
    "def train_and_predict(X_train, X_test, y_train, y_test):\n",
    "    predictions = np.zeros_like(y_test)\n",
    "    for i, label in enumerate(y_train.columns):\n",
    "        print(f'Training model for label: {label}')\n",
    "        lgb_train = lgb.Dataset(X_train, y_train.iloc[:, i])\n",
    "        lgb_eval = lgb.Dataset(X_test, y_test.iloc[:, i], reference=lgb_train)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9\n",
    "        }\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=100,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        callbacks=[early_stopping_callback])\n",
    "\n",
    "        y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "        predictions[:, i] = (y_pred > 0.5).astype(int)\n",
    "    return predictions\n",
    "\n",
    "# Train the model and get predictions\n",
    "y_pred = train_and_predict(x_train, x_test, y_train, y_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred, target_names=list(y_train.columns))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339807c-6457-4d27-9229-0626d1cf3e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa440371-695a-4e1a-9818-d6d196a31df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.13\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Action       0.79      0.42      0.55       636\n",
      "Action/Adventure       0.72      0.37      0.49       599\n",
      "       Adventure       0.78      0.36      0.50       546\n",
      " Black-and-white       0.86      0.20      0.32       455\n",
      "          Comedy       0.75      0.27      0.40       728\n",
      "   Crime Fiction       0.81      0.37      0.51       435\n",
      "           Drama       0.69      0.45      0.55       986\n",
      "     Family Film       0.82      0.42      0.56       444\n",
      "          Horror       0.86      0.56      0.68       596\n",
      "           Indie       0.84      0.07      0.13       454\n",
      "    Romance Film       0.67      0.28      0.40       364\n",
      "      Short Film       0.87      0.54      0.67       582\n",
      "        Thriller       0.77      0.34      0.47       583\n",
      "    World cinema       0.81      0.12      0.21       423\n",
      "\n",
      "       micro avg       0.78      0.36      0.49      7831\n",
      "       macro avg       0.79      0.34      0.46      7831\n",
      "    weighted avg       0.78      0.36      0.47      7831\n",
      "     samples avg       0.53      0.36      0.40      7831\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asolta2s/myenv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred, target_names=list(y_train.columns))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab3caa-e542-4014-b60d-474989c4fd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
