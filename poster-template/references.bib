%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for amir at 2024-06-21 11:43:26 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@article{MA2022115905,
	abstract = {Many real-world text classification tasks often deal with a large number of closely related categories organized in a hierarchical structure or taxonomy. Hierarchical multi-label text classification (HMTC) has become rather challenging when it requires handling large sets of closely related categories. The structural features of all categories in the entire hierarchy and the word semantics of their category labels are very helpful in improving text classification accuracy over large sets of closely related categories, which has been neglected in most of existing HMTC approaches. In this paper, we present a hybrid embedding-based text representation for HMTC with high accuracy. First, the hybrid embedding consists of both graph embedding of categories in the hierarchy and their word embedding of category labels. The Structural Deep Network Embedding-based graph embedding model is used to simultaneously encode the global and local structural features of a given category in the whole hierarchy for making the category structurally discriminable. We further use the word embedding technique to encode the word semantics of each category label in the hierarchy for making different categories semantically discriminable. Second, we presented a level-by-level HMTC approach based on the bidirectional Gated Recurrent Unit network model together with the hybrid embedding that is used to learn the representation of the text level-by-level. Last but not least, extensive experiments were made over five large-scale real-world datasets in comparison with the state-of-the-art hierarchical and flat multi-label text classification approaches, and the experimental results show that our approach is very competitive to the state-of-the-art approaches in classification accuracy, in particular maintaining computational costs while achieving superior performance.},
	author = {Yinglong Ma and Xiaofeng Liu and Lijiao Zhao and Yue Liang and Peng Zhang and Beihong Jin},
	date-added = {2024-06-21 11:43:08 +0200},
	date-modified = {2024-06-21 11:43:08 +0200},
	doi = {https://doi.org/10.1016/j.eswa.2021.115905},
	issn = {0957-4174},
	journal = {Expert Systems with Applications},
	keywords = {Hierarchical classification, Text classification, Multi-label classification, Graph embedding, Hybrid embedding},
	pages = {115905},
	title = {Hybrid embedding-based text representation for hierarchical multi-label text classification},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417421012604},
	volume = {187},
	year = {2022},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0957417421012604},
	bdsk-url-2 = {https://doi.org/10.1016/j.eswa.2021.115905}}

@article{9169885,
	author = {Cai, Linkun and Song, Yu and Liu, Tao and Zhang, Kunli},
	date-added = {2024-06-21 11:42:45 +0200},
	date-modified = {2024-06-21 11:42:45 +0200},
	doi = {10.1109/ACCESS.2020.3017382},
	journal = {IEEE Access},
	keywords = {Semantics;Task analysis;Bit error rate;Correlation;Computational modeling;Neural networks;Prediction algorithms;Multi-label text classification;label embedding;BERT;attention mechanism},
	pages = {152183-152192},
	title = {A Hybrid BERT Model That Incorporates Label Semantics via Adjustive Attention for Multi-Label Text Classification},
	volume = {8},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1109/ACCESS.2020.3017382}}
